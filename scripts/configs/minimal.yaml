seed_everything: 35
data:
  class_path: eigenn.dataset.matbench.MatbenchDataMoldule
  init_args:
    trainset_filename: matbench_dielectric_val.json
    valset_filename: matbench_dielectric_val.json
    testset_filename: matbench_dielectric_val.json
    r_cut: 5.0
    root: /Users/mjwen/Documents/Dataset/matbench/matbench_dielectric
    loader_kwargs:
      batch_size: 10

model:
  backbone_hparams:
    num_layers: 3
    r_max: 4
    species_embedding_irreps_out: 16x0e
    feature_irreps_hidden: 32x0o + 32x0e + 16x1o + 16x1e
    irreps_edge_sh: 0e + 1o
  task_hparams:
    task_name: n

trainer:
  max_epochs: 5
  checkpoint_callback: true
  num_nodes: 1
  num_processes: 1
  flush_logs_every_n_steps: 100
  log_every_n_steps: 50
  sync_batchnorm: false
  weights_summary: top
  num_sanity_val_steps: 2
  terminate_on_nan: false
  precision: 32
  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val/score
        mode: min
        save_top_k: 3
        save_last: true
        verbose: False
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val/score
        mode: min
        patience: 100
        min_delta: 0
        verbose: true
  logger:
    class_path: pytorch_lightning.loggers.wandb.WandbLogger
    init_args:
      save_dir: wandb_logs # should be provided to make cli save config work
      project: tmp-eigenn

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.001
    betas:
      - 0.9
      - 0.999
    eps: 1.0e-08
    weight_decay: 0
    amsgrad: false

lr_scheduler:
  class_path: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR
  init_args:
    warmup_epochs: 10
    max_epochs: 20 # this should be set to trainer.max_epochs
    warmup_start_lr: 0.0
    eta_min: 0.0
    last_epoch: -1
